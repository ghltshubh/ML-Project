{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING - HOMEWORK 1\n",
    "Team Members: <ul><li>Shubham Bothara A20383550\n",
    "<li>Shubhankar Gahlot A20340059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV, RidgeCV, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import KFold   \n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\tDecision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\tCreate a new field “highCrime” which is true if the crime rate per capita (ViolentCrimesPerPop) is greater than 0.1, and false otherwise. What are the percentage of positive and negative instances in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of positive instance: 62.7382146439\n",
      "Percent of negative instance: 37.2617853561\n"
     ]
    }
   ],
   "source": [
    "cleanData = pd.read_csv(\"communities-crime-clean.csv\")\n",
    "cleanData['highCrime'] = 0\n",
    "condition = cleanData['ViolentCrimesPerPop'] > 0.1\n",
    "cleanData.loc[condition, 'highCrime'] = 1\n",
    "PercentageOfHighCrime = cleanData['highCrime'].value_counts()/cleanData['highCrime'].count()*100\n",
    "percentPositiveInstance = PercentageOfHighCrime[1]\n",
    "percentNegativeInstance = PercentageOfHighCrime[0]\n",
    "print('Percent of positive instance: ' + str(percentPositiveInstance))\n",
    "print('Percent of negative instance: ' + str(percentNegativeInstance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\t Use DecisionTreeClassifier to learn a decision tree to predict highCrime on the entire dataset\n",
    "\n",
    "We tried this in 3 ways with :<ol><li> same Training and Testing Data \\n\n",
    "                              <li> pruning trees to max level 3 and, \n",
    "                              <li> 80:20 Train data : Test data split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.\tWhat are the training accuracy, precision, and recall for this tree? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 100.000%\n",
      "Precision : 100.000%\n",
      "Recall : 100.000%\n"
     ]
    }
   ],
   "source": [
    "cleanDataDT = cleanData.drop(['fold','state','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "outcome = 'highCrime'\n",
    "predictors = list(cleanDataDT)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "decisionTree = tree.DecisionTreeClassifier()\n",
    "decisionTree = decisionTree.fit(cleanDataDT[predictors], cleanData[outcome])\n",
    "prediction = decisionTree.predict(cleanDataDT[predictors])\n",
    "accuracy = metrics.accuracy_score(prediction,cleanDataDT[outcome])\n",
    "print ('Accuracy : %s' % '{0:.3%}'.format(accuracy))   \n",
    "    \n",
    "precision = metrics.precision_score(prediction,cleanDataDT[outcome])\n",
    "print ('Precision : %s' % '{0:.3%}'.format(precision))   \n",
    "\n",
    "recall = metrics.recall_score(prediction,cleanDataDT[outcome])\n",
    "print ('Recall : %s' % '{0:.3%}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 83.601%\n",
      "Precision : 83.054%\n",
      "Recall : 90.035%\n"
     ]
    }
   ],
   "source": [
    "cleanDataDT = cleanData.drop(['fold','state','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "outcome = 'highCrime'\n",
    "predictors = list(cleanDataDT)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "decisionTree = tree.DecisionTreeClassifier(max_depth=3)\n",
    "decisionTree = decisionTree.fit(cleanDataDT[predictors], cleanData[outcome])\n",
    "prediction = decisionTree.predict(cleanDataDT[predictors])\n",
    "accuracy = metrics.accuracy_score(prediction,cleanDataDT[outcome])\n",
    "print ('Accuracy : %s' % '{0:.3%}'.format(accuracy))   \n",
    "    \n",
    "precision = metrics.precision_score(prediction,cleanDataDT[outcome])\n",
    "print ('Precision : %s' % '{0:.3%}'.format(precision))   \n",
    "\n",
    "recall = metrics.recall_score(prediction,cleanDataDT[outcome])\n",
    "print ('Recall : %s' % '{0:.3%}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For data split in 80 train - 20 test\n",
      "Accuracy : 83.208%\n",
      "Precision : 84.490%\n",
      "Recall : 87.712%\n"
     ]
    }
   ],
   "source": [
    "train, test = np.split(cleanDataDT.sample(frac=1), [ int(.8*len(cleanDataDT))])\n",
    "decisionTree2 = decisionTree.fit(train[predictors], train[outcome])\n",
    "\n",
    "print(\"For data split in 80 train - 20 test\")\n",
    "prediction = decisionTree2.predict(test[predictors])\n",
    "accuracy = metrics.accuracy_score(prediction,test[outcome])\n",
    "print ('Accuracy : %s' % '{0:.3%}'.format(accuracy))   \n",
    "    \n",
    "precision = metrics.precision_score(prediction,test[outcome])\n",
    "print ('Precision : %s' % '{0:.3%}'.format(precision))   \n",
    "\n",
    "recall = metrics.recall_score(prediction,test[outcome])\n",
    "print ('Recall : %s' % '{0:.3%}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.\tWhat are the main features used for classification? Can you explain why they make sense (or not)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Top 10 features selected by decision tree are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>featureName</th>\n",
       "      <th>infoGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>0.628694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>0.239345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>racePctHisp</td>\n",
       "      <td>0.104565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>PctFam2Par</td>\n",
       "      <td>0.027396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>population</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>PersPerOccupHous</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>PctHousOwnOcc</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>PctHousOccup</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>HousVacant</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>MedNumBR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         featureName  infoGain\n",
       "44       PctKids2Par  0.628694\n",
       "3       racePctWhite  0.239345\n",
       "5        racePctHisp  0.104565\n",
       "43        PctFam2Par  0.027396\n",
       "0         population  0.000000\n",
       "64  PersPerOccupHous  0.000000\n",
       "73     PctHousOwnOcc  0.000000\n",
       "72      PctHousOccup  0.000000\n",
       "71        HousVacant  0.000000\n",
       "70          MedNumBR  0.000000"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best features\n",
    "impFeatureDf = pd.DataFrame(columns=['featureName','infoGain'])\n",
    "feature = np.array(cleanDataDT.columns)\n",
    "impFeatureDf['featureName'] = np.array(cleanDataDT[predictors].columns)\n",
    "impFeatureDf['infoGain'] = decisionTree.feature_importances_\n",
    "print ('The Top 10 features selected by decision tree are: ')\n",
    "impFeatureDf.sort_values('infoGain', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split on PctKids2Par makes sense because the families prefer to choose to live in localities with low crime.\n",
    "The split on PctEmploy makes sense because the employment tends to reduce crime rate.\n",
    "The split on PctLess9thGrade makes sense because of lack of education people might be forced into commiting crime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\tNow apply cross-validation (cross_val_score) to do 10-fold cross-validation to estimate the out-of-training accuracy of decision tree learning for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.\tWhat are the 10-fold cross-validation accuracy, precision, and recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the decision tree classifier is:\n",
      "[ 0.81094527  0.755       0.75        0.75879397  0.70351759  0.74874372\n",
      "  0.81407035  0.74874372  0.72864322  0.73366834] \n",
      "And their mean is:\n",
      "  0.755212617815\n",
      "\n",
      "The 10 Fold precision of the decision tree classifier is:\n",
      "[ 0.83606557  0.83050847  0.78151261  0.81102362  0.79661017  0.82926829\n",
      "  0.8442623   0.81896552  0.79487179  0.79674797] \n",
      "And their mean is:\n",
      "  0.813983631229\n",
      "\n",
      "The 10 Fold recall of the decision tree classifier is:\n",
      " [ 0.84126984  0.808       0.768       0.792       0.776       0.792       0.848\n",
      "  0.8         0.792       0.776     ] \n",
      "And their mean is:\n",
      "  0.799326984127\n"
     ]
    }
   ],
   "source": [
    "# import random\n",
    "# random.seed(3213)\n",
    "decisionTree = tree.DecisionTreeClassifier()\n",
    "\n",
    "kFoldAccuracy = model_selection.cross_val_score(decisionTree, cleanDataDT[predictors], cleanDataDT[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(decisionTree, cleanDataDT[predictors], cleanDataDT[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(decisionTree, cleanDataDT[predictors], cleanDataDT[outcome], cv=10, scoring='recall')\n",
    "\n",
    "\n",
    "print ('The 10 Fold accuracy of the decision tree classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the decision tree classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the decision tree classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii.\tWhy are they different from the results in the previous test?\n",
    "\n",
    "This difference in the results is because the variance of the resulting estimate is reduced as number of folds is increased and decrease in variance helps reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.\tLinear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\tUse GaussianNB to learn a Naive Bayes classifier to predict highCrime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanDataNB = cleanData.drop(['state','fold','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "NB = GaussianNB()\n",
    "\n",
    "NB = NB.fit(cleanDataNB[predictors], cleanData[outcome])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.\tWhat is the 10-fold cross-validation accuracy, precision, and recall for this method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the naive baye's classifier is:\n",
      "[ 0.80099502  0.79        0.8         0.76884422  0.76884422  0.77386935\n",
      "  0.8040201   0.75376884  0.77889447  0.73366834] \n",
      "And their mean is:\n",
      "  0.777290457261\n",
      "\n",
      "The 10 Fold precision of the naive baye's classifier is:\n",
      "[ 0.93877551  0.8952381   0.95698925  0.8989899   0.94382022  0.92553191\n",
      "  0.97777778  0.93181818  0.92631579  0.90909091] \n",
      "And their mean is:\n",
      "  0.930434754952\n",
      "\n",
      "The 10 Fold recall of the naive baye's classifier is:\n",
      " [ 0.73015873  0.752       0.712       0.712       0.672       0.696       0.704\n",
      "  0.656       0.704       0.64      ] \n",
      "And their mean is:\n",
      "  0.697815873016\n"
     ]
    }
   ],
   "source": [
    "kFoldAccuracy = model_selection.cross_val_score(NB, cleanDataNB[predictors], cleanDataNB[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(NB, cleanDataNB[predictors], cleanDataNB[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(NB, cleanDataNB[predictors], cleanDataNB[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the naive baye\\'s classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the naive baye\\'s classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the naive baye\\'s classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.\tWhat are the 10 most predictive features? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Naive Baye's features are:\n",
      "1: PctKids2Par\n",
      "2: FemalePctDiv\n",
      "3: PctFam2Par\n",
      "4: pctWInvInc\n",
      "5: TotalPctDiv\n",
      "6: PctTeen2Par\n",
      "7: MalePctDivorce\n",
      "8: PctYoungKids2Par\n",
      "9: PctIlleg\n",
      "10: racePctWhite\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for i in range(0,len(predictors)-1):\n",
    "    info = []\n",
    "    info.append(abs(NB.theta_[0, i] - NB.theta_[1, i])/(NB.sigma_[0, i] + NB.sigma_[1, i]))\n",
    "    info.append(predictors[i])\n",
    "    features.append(info)\n",
    "\n",
    "features.sort(reverse=True)\n",
    "\n",
    "topTenNBFeatures = features[:10]\n",
    "print(\"Top 10 Naive Baye's features are:\")\n",
    "index = 1\n",
    "for i in topTenNBFeatures:\n",
    "    print(str(index) + \": \" + i[1])\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii.\tHow do these results compare with your results from decision trees, above?\n",
    "\n",
    "Compared to Decision tree, Naive Bayes has different top ten most informative features except for PctKids2Par and racePctWhite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\tUse LinearSVC to learn a linear Support Vector Machine model to predict highCrime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanDataSVC = cleanData.drop(['state','fold','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "SVC = LinearSVC()\n",
    "\n",
    "SVC = SVC.fit(cleanDataSVC[predictors], cleanData[outcome])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.\t What is the 10-fold cross-validation accuracy, precision, and recall for this method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the Linear SVC classifier is:\n",
      "[ 0.85572139  0.815       0.825       0.83417085  0.8241206   0.80904523\n",
      "  0.86432161  0.83417085  0.8040201   0.83417085] \n",
      "And their mean is:\n",
      "  0.829974149354\n",
      "\n",
      "The 10 Fold precision of the Linear SVC classifier is:\n",
      "[ 0.90082645  0.83846154  0.86290323  0.86507937  0.875       0.85365854\n",
      "  0.88888889  0.88983051  0.84126984  0.86507937] \n",
      "And their mean is:\n",
      "  0.868099771593\n",
      "\n",
      "The 10 Fold recall of the Linear SVC classifier is:\n",
      " [ 0.86507937  0.872       0.856       0.872       0.84        0.84        0.896\n",
      "  0.84        0.848       0.872     ] \n",
      "And their mean is:\n",
      "  0.860107936508\n"
     ]
    }
   ],
   "source": [
    "kFoldAccuracy = model_selection.cross_val_score(SVC, cleanDataSVC[predictors], cleanDataSVC[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(SVC, cleanDataSVC[predictors], cleanDataSVC[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(SVC, cleanDataSVC[predictors], cleanDataSVC[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the Linear SVC classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the Linear SVC classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the Linear SVC classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### ii.\tWhat are the 10 most predictive features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 SVC features are:\n",
      "1: pctWInvInc\n",
      "2: PersPerOccupHous\n",
      "3: racePctWhite\n",
      "4: PctKids2Par\n",
      "5: RentHighQ\n",
      "6: MalePctDivorce\n",
      "7: NumUnderPov\n",
      "8: NumStreet\n",
      "9: PctOccupMgmtProf\n",
      "10: population\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for i in range(0,len(predictors)-1):\n",
    "    info = []\n",
    "    info.append(abs(SVC.coef_[0][i]))\n",
    "    info.append(predictors[i])\n",
    "    features.append(info)\n",
    "\n",
    "features.sort(reverse=True)\n",
    "topTenSVCFeatures = features[:10]\n",
    "print(\"Top 10 SVC features are:\")\n",
    "index = 1\n",
    "for i in topTenSVCFeatures:\n",
    "    print(str(index) + \": \" + i[1])\n",
    "    index = index + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split on PctKids2Par makes sense because the families prefer to choose to live in localities with low crime.\n",
    "The split on PctEmploy makes sense because the employment tends to reduce crime rate.\n",
    "The split on PctLess9thGrade makes sense because of lack of education people might be forced into commiting crime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii.\tHow do these results compare with your results from decision trees, above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to Decision tree, Linear SVC has top ten new most informative features except for PctKids2Par and racePctWhite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\tRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\tUse LinearRegression to learn a linear model directly predicting the crime rate per capita (ViolentCrimesPerPop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcome = 'ViolentCrimesPerPop'\n",
    "cleanDataLR = cleanData.drop(['state','fold','communityname','highCrime'], axis=1)\n",
    "predictors = list(cleanDataLR)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "LR = LinearRegression()\n",
    "\n",
    "LR = LR.fit(cleanDataLR[predictors], cleanData[outcome])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.\tUsing 10-fold cross-validation, what is the estimated mean-squared-error (MSE) of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold mean squared error of the Linear regression is:\n",
      "[ 0.02164175  0.01853214  0.02612987  0.01974299  0.0174234   0.01538316\n",
      "  0.01614152  0.01534365  0.01691999  0.01845021] \n",
      "And their mean is:\n",
      "  0.0185708681157\n"
     ]
    }
   ],
   "source": [
    "kFoldMSE = model_selection.cross_val_score(LR, cleanDataLR[predictors], cleanDataLR[outcome], cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "print ('The 10 Fold mean squared error of the Linear regression is:\\n%s \\nAnd their mean is:\\n '%(str(abs(kFoldMSE))), abs(np.mean(kFoldMSE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.\tWhat is the MSE on the training set (train on all the data then test on it all)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 1.656%\n"
     ]
    }
   ],
   "source": [
    "prediction = LR.predict(cleanDataLR[predictors])\n",
    "mse = metrics.mean_squared_error(prediction,cleanDataLR[outcome])\n",
    "print ('MSE : %s' % '{0:.3%}'.format(mse))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii.\tWhat features are most predictive of a high crime rate? A low crime rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High crime features: \n",
      "1: PersPerOccupHous\n",
      "2: PctHousOwnOcc\n",
      "3: MalePctDivorce\n",
      "4: PctRecImmig8\n",
      "5: MedRent\n",
      "6: medFamInc\n",
      "7: PctEmploy\n",
      "8: MalePctNevMarr\n",
      "9: PctPersDenseHous\n",
      "10: OwnOccMedVal\n",
      "\n",
      "Low crime features: \n",
      "1: PctPersOwnOccup\n",
      "2: TotalPctDiv\n",
      "3: whitePerCap\n",
      "4: PctKids2Par\n",
      "5: OwnOccLowQuart\n",
      "6: numbUrban\n",
      "7: PersPerRentOccHous\n",
      "8: RentLowQ\n",
      "9: agePct12t29\n",
      "10: PctRecImmig5\n"
     ]
    }
   ],
   "source": [
    "highCrimeFeatures = []\n",
    "lowCrimeFeatures = []\n",
    "for i in range(0,len(predictors)-1):\n",
    "    info = []\n",
    "    info.append(abs(LR.coef_[i]))\n",
    "    info.append(predictors[i])\n",
    "    if(LR.coef_[i] > 0):\n",
    "        highCrimeFeatures.append(info)\n",
    "    else:\n",
    "        lowCrimeFeatures.append(info)\n",
    "\n",
    "highCrimeFeatures.sort(reverse=True)\n",
    "topTenHighCrimeFeatures = highCrimeFeatures[:10]\n",
    "lowCrimeFeatures.sort(reverse=True)\n",
    "topTenLowCrimeFeatures = lowCrimeFeatures[:10]\n",
    "print(\"High crime features: \")\n",
    "index = 1\n",
    "for i in topTenHighCrimeFeatures:\n",
    "    print(str(index) + \": \" + i[1])\n",
    "    index = index + 1\n",
    "\n",
    "print(\"\\nLow crime features: \")\n",
    "index = 1\n",
    "for i in topTenLowCrimeFeatures:\n",
    "    print(str(index) + \": \" + i[1])\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\tNow use Ridge regression to reduce the amount of overfitting, using RidgeCV to pick the best alpha from among (10, 1, 0.1, 0.01, and 0.001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ridgeCV we determined the best alpha to be : 1.0\n"
     ]
    }
   ],
   "source": [
    "cleanDataRidge = cleanData.drop(['state','communityname','highCrime','fold'], axis=1)\n",
    "#print(cleanDataRidge)\n",
    "alpha = np.array([10,1,0.1,0.01,0.001])\n",
    "\n",
    "ridgeCV = RidgeCV(alpha, cv=10)\n",
    "#print(ridgeCV)\n",
    "ridgeCV = ridgeCV.fit(cleanDataRidge[predictors], cleanData[outcome])\n",
    "prediction = ridgeCV.predict(cleanDataRidge[predictors])\n",
    "alpha= ridgeCV.alpha_\n",
    "print(\"Using ridgeCV we determined the best alpha to be :\",alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.\tWhat is the estimated MSE of the model under 10-fold CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold mean squared error of the Ridge is:\n",
      "[ 0.02150699  0.01838653  0.02555132  0.01953837  0.01730767  0.01454866\n",
      "  0.01619059  0.01557036  0.01663208  0.01792579] \n",
      "And their mean is:\n",
      "  0.0183158369331\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha)\n",
    "ridge.fit(cleanDataRidge[predictors], cleanData[outcome])\n",
    "prediction2 = ridge.predict(cleanDataRidge[predictors])\n",
    "\n",
    "kFoldMSE = model_selection.cross_val_score(ridge, cleanDataRidge[predictors], cleanDataRidge[outcome], cv=10, scoring='neg_mean_squared_error')\n",
    "print ('The 10 Fold mean squared error of the Ridge is:\\n%s \\nAnd their mean is:\\n '%(str(abs(kFoldMSE))), abs(np.mean(kFoldMSE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.\tWhat is the MSE on the training set (train on all the data then test on it all)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 1.681%\n"
     ]
    }
   ],
   "source": [
    "prediction = ridge.predict(cleanDataRidge[predictors])\n",
    "mse = metrics.mean_squared_error(prediction,cleanDataRidge[outcome])\n",
    "print ('MSE : %s' % '{0:.3%}'.format(mse)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii.\tWhat is the best alpha?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha is: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Best alpha is: \" + str(alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv.\tWhat does this say about the amount of overfitting in linear regression for this problem?\n",
    "\n",
    "As the best alpha is really low this implies that the penalty for features is low therefore this should lead to lower overfitting in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\tNow use polynomial features to do quadratic (second-order) polynomial regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of second order dataset is:  (1994, 5253)\n"
     ]
    }
   ],
   "source": [
    "outcome = 'ViolentCrimesPerPop'\n",
    "cleanDataPoly = cleanData.drop(['state','communityname','highCrime','fold'], axis=1)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "polyFeatures = poly.fit_transform(cleanDataPoly)\n",
    "print(\"The shape of second order dataset is: \" ,polyFeatures.shape)\n",
    "polyLR = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.\tWhat is the estimated MSE of the model under 10-fold CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold mean squared error of the Ridge is:\n",
      "[  1.61193243e-05   2.41294145e-05   1.77612871e-05   1.52582332e-05\n",
      "   1.51364037e-05   2.83004185e-05   2.24681664e-05   1.62962803e-05\n",
      "   1.86661833e-05   1.24359614e-05] \n",
      "And their mean is:\n",
      "  1.86571672512e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kFoldMSE = model_selection.cross_val_score(polyLR, polyFeatures, cleanDataPoly[outcome], cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "print ('The 10 Fold mean squared error of the Ridge is:\\n%s \\nAnd their mean is:\\n '%(str(abs(kFoldMSE))), abs(np.mean(kFoldMSE)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.\tWhat is the MSE on the training set (train on all the data then test on it all)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.000%\n"
     ]
    }
   ],
   "source": [
    "polyLR = polyLR.fit(polyFeatures, cleanData[outcome])\n",
    "\n",
    "prediction = polyLR.predict(polyFeatures)\n",
    "mse = metrics.mean_squared_error(prediction,cleanDataPoly[outcome])\n",
    "print ('MSE : %s' % '{0:.3%}'.format(mse)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii.\tDoes this mean the quadratic model is better than the linear model for this problem?\n",
    "\n",
    "From the above two outcomes we can see that the MSE is very low for quadratic model, therefore it is a better model than the linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\tDirty Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\tCreate a new field “highCrime” which is true if the crime rate per capita (ViolentCrimesPerPop) is greater than 0.1, and false otherwise. What are the percentage of positive and negative instances in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of positive instance: 62.7382146439\n",
      "Percent of negative instance: 37.2617853561\n"
     ]
    }
   ],
   "source": [
    "dirtyData = pd.read_csv(\"communities-crime-full.csv\",na_values='?')\n",
    "dirtyData.fillna(dirtyData.mean(),inplace=True)\n",
    "dirtyData = dirtyData.drop(['county','fold','state','community','communityname'], axis=1)\n",
    "\n",
    "dirtyData['highCrime'] = 0\n",
    "condition = dirtyData['ViolentCrimesPerPop'] > 0.1\n",
    "dirtyData.loc[condition, 'highCrime'] = 1\n",
    "\n",
    "PercentageOfHighCrime = dirtyData['highCrime'].value_counts()/dirtyData['highCrime'].count()*100\n",
    "percentPositiveInstance = PercentageOfHighCrime[1]\n",
    "percentNegativeInstance = PercentageOfHighCrime[0]\n",
    "print('Percent of positive instance: ' + str(percentPositiveInstance))\n",
    "print('Percent of negative instance: ' + str(percentNegativeInstance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\t Use DecisionTreeClassifier to learn a decision tree to predict highCrime on the entire dataset\n",
    "\n",
    "We tried this in 3 ways with :<ul><li> same Training and Testing Data\n",
    "                              <li> pruning trees to max level 3 and, \n",
    "                              <li> 80:20 Train data : Test data split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.\tWhat are the training accuracy, precision, and recall for this tree? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 100.000%\n",
      "Precision : 100.000%\n",
      "Recall : 100.000%\n"
     ]
    }
   ],
   "source": [
    "dirtyDataDT = dirtyData.drop(['ViolentCrimesPerPop'], axis=1)\n",
    "outcome = 'highCrime'\n",
    "predictors = list(dirtyDataDT)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "decisionTree = tree.DecisionTreeClassifier()\n",
    "decisionTree = decisionTree.fit(dirtyDataDT[predictors], dirtyData[outcome])\n",
    "prediction = decisionTree.predict(dirtyDataDT[predictors])\n",
    "accuracy = metrics.accuracy_score(prediction,dirtyDataDT[outcome])\n",
    "print ('Accuracy : %s' % '{0:.3%}'.format(accuracy))   \n",
    "    \n",
    "precision = metrics.precision_score(prediction,dirtyDataDT[outcome])\n",
    "print ('Precision : %s' % '{0:.3%}'.format(precision))   \n",
    "\n",
    "recall = metrics.recall_score(prediction,dirtyDataDT[outcome])\n",
    "print ('Recall : %s' % '{0:.3%}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 83.601%\n",
      "Precision : 83.054%\n",
      "Recall : 90.035%\n"
     ]
    }
   ],
   "source": [
    "dirtyDataDT = dirtyData.drop(['ViolentCrimesPerPop'], axis=1)\n",
    "outcome = 'highCrime'\n",
    "predictors = list(dirtyDataDT)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "decisionTree = tree.DecisionTreeClassifier(max_depth=3)\n",
    "decisionTree = decisionTree.fit(dirtyDataDT[predictors], dirtyData[outcome])\n",
    "prediction = decisionTree.predict(dirtyDataDT[predictors])\n",
    "accuracy = metrics.accuracy_score(prediction,dirtyDataDT[outcome])\n",
    "print ('Accuracy : %s' % '{0:.3%}'.format(accuracy))   \n",
    "    \n",
    "precision = metrics.precision_score(prediction,dirtyDataDT[outcome])\n",
    "print ('Precision : %s' % '{0:.3%}'.format(precision))   \n",
    "\n",
    "recall = metrics.recall_score(prediction,dirtyDataDT[outcome])\n",
    "print ('Recall : %s' % '{0:.3%}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For data split in 80 train - 20 test\n",
      "Accuracy : 83.459%\n",
      "Precision : 88.462%\n",
      "Recall : 86.466%\n"
     ]
    }
   ],
   "source": [
    "train, test = np.split(dirtyDataDT.sample(frac=1), [ int(.8*len(dirtyDataDT))])\n",
    "decisionTree2 = decisionTree.fit(train[predictors], train[outcome])\n",
    "\n",
    "print(\"For data split in 80 train - 20 test\")\n",
    "prediction = decisionTree2.predict(test[predictors])\n",
    "accuracy = metrics.accuracy_score(prediction,test[outcome])\n",
    "print ('Accuracy : %s' % '{0:.3%}'.format(accuracy))   \n",
    "    \n",
    "precision = metrics.precision_score(prediction,test[outcome])\n",
    "print ('Precision : %s' % '{0:.3%}'.format(precision))   \n",
    "\n",
    "recall = metrics.recall_score(prediction,test[outcome])\n",
    "print ('Recall : %s' % '{0:.3%}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.\tWhat are the main features used for classification? Can you explain why they make sense (or not)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Top 10 features selected by decision tree are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>featureName</th>\n",
       "      <th>infoGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>0.758619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>0.161143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>racePctHisp</td>\n",
       "      <td>0.040541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NumImmig</td>\n",
       "      <td>0.020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>HousVacant</td>\n",
       "      <td>0.019077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>population</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>OwnOccMedVal</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>OwnOccHiQuart</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>RentLowQ</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>RentMedian</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      featureName  infoGain\n",
       "44    PctKids2Par  0.758619\n",
       "3    racePctWhite  0.161143\n",
       "5     racePctHisp  0.040541\n",
       "51       NumImmig  0.020621\n",
       "71     HousVacant  0.019077\n",
       "0      population  0.000000\n",
       "80   OwnOccMedVal  0.000000\n",
       "81  OwnOccHiQuart  0.000000\n",
       "82       RentLowQ  0.000000\n",
       "83     RentMedian  0.000000"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best features\n",
    "impFeatureDf = pd.DataFrame(columns=['featureName','infoGain'])\n",
    "feature = np.array(dirtyDataDT.columns)\n",
    "impFeatureDf['featureName'] = np.array(dirtyDataDT[predictors].columns)\n",
    "impFeatureDf['infoGain'] = decisionTree.feature_importances_\n",
    "print ('The Top 10 features selected by decision tree are: ')\n",
    "impFeatureDf.sort_values('infoGain', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split on PctKids2Par makes sense because the families prefer to choose to live in localities with low crime.\n",
    "The split on PctEmploy makes sense because the employment tends to reduce crime rate.\n",
    "The split on PctLess9thGrade makes sense because of lack of education people might be forced into commiting crime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\tNow apply cross-validation (cross_val_score) to do 10-fold cross-validation to estimate the out-of-training accuracy of decision tree learning for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.\tWhat are the 10-fold cross-validation accuracy, precision, and recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the decision tree classifier is:\n",
      "[ 0.81094527  0.81        0.805       0.79899497  0.82914573  0.77386935\n",
      "  0.85427136  0.83417085  0.80904523  0.8040201 ] \n",
      "And their mean is:\n",
      "  0.812946286157\n",
      "\n",
      "The 10 Fold precision of the decision tree classifier is:\n",
      "[ 0.90740741  0.85365854  0.84677419  0.84        0.85826772  0.85714286\n",
      "  0.92105263  0.92592593  0.85950413  0.90566038] \n",
      "And their mean is:\n",
      "  0.877539377831\n",
      "\n",
      "The 10 Fold recall of the decision tree classifier is:\n",
      " [ 0.77777778  0.84        0.84        0.84        0.872       0.768       0.84\n",
      "  0.8         0.832       0.768     ] \n",
      "And their mean is:\n",
      "  0.817777777778\n"
     ]
    }
   ],
   "source": [
    "kFoldAccuracy = model_selection.cross_val_score(decisionTree2, dirtyDataDT[predictors], dirtyDataDT[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(decisionTree2, dirtyDataDT[predictors], dirtyDataDT[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(decisionTree2, dirtyDataDT[predictors], dirtyDataDT[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the decision tree classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the decision tree classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the decision tree classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.\tWhy are they different from the results in the previous test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are different than the previous models because in the first case we were training and testing on the same data set hence seeing 100% accuracy. With the other two scenarios\n",
    "\n",
    "This difference is because the variance of the resulting estimate is reduced as number of folds is increased and decrease in variance helps reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\tTeams "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\tIf you are working in a team of two people:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.\tExperiment with two learning methods other than those described above (one can be a non-linear kernel for SVM) for the classification problem, explaining clearly what you did. Show CV results for both the clean and full datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the Logistic regression is:\n",
      "[ 0.84079602  0.83        0.845       0.82914573  0.8241206   0.83417085\n",
      "  0.85427136  0.83417085  0.79899497  0.81407035] \n",
      "And their mean is:\n",
      "  0.830474074352\n",
      "\n",
      "The 10 Fold precision of the Logistic regression classifier is:\n",
      "[ 0.8852459   0.85826772  0.87301587  0.85271318  0.86885246  0.85384615\n",
      "  0.89344262  0.88983051  0.84        0.84920635] \n",
      "And their mean is:\n",
      "  0.866442076298\n",
      "\n",
      "The 10 Fold recall of the Logistic regression classifier is:\n",
      " [ 0.85714286  0.872       0.88        0.88        0.848       0.888       0.872\n",
      "  0.84        0.84        0.856     ] \n",
      "And their mean is:\n",
      "  0.863314285714\n"
     ]
    }
   ],
   "source": [
    "#1 Logistic Regression with clean Data\n",
    "outcome = 'highCrime'\n",
    "cleanDataLogit = cleanData.drop(['state','fold','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "predictors = list(cleanDataLogit)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "logit = LogisticRegressionCV()\n",
    "\n",
    "logit = logit.fit(cleanDataLogit[predictors], cleanData[outcome])\n",
    "kFoldAccuracy = model_selection.cross_val_score(logit, cleanDataLogit[predictors], cleanDataLogit[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(logit, cleanDataLogit[predictors], cleanDataLogit[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(logit, cleanDataLogit[predictors], cleanDataLogit[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the Logistic regression is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the Logistic regression classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the Logistic regression classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the Logistic regression is:\n",
      "[ 0.84577114  0.83        0.845       0.83417085  0.8241206   0.83417085\n",
      "  0.84924623  0.83417085  0.79899497  0.83919598] \n",
      "And their mean is:\n",
      "  0.833484149604\n",
      "\n",
      "The 10 Fold precision of the Logistic regression classifier is:\n",
      "[ 0.88617886  0.85826772  0.87301587  0.859375    0.86885246  0.85384615\n",
      "  0.88617886  0.88983051  0.84        0.86046512] \n",
      "And their mean is:\n",
      "  0.867601055074\n",
      "\n",
      "The 10 Fold recall of the Logistic regression classifier is:\n",
      " [ 0.86507937  0.872       0.88        0.88        0.848       0.888       0.872\n",
      "  0.84        0.84        0.888     ] \n",
      "And their mean is:\n",
      "  0.867307936508\n"
     ]
    }
   ],
   "source": [
    "#2 Logistic Regression with full data\n",
    "outcome = 'highCrime'\n",
    "dirtyDataLogit = dirtyData.drop(['ViolentCrimesPerPop'], axis=1)\n",
    "predictors = list(dirtyDataLogit)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "logit = LogisticRegressionCV()\n",
    "\n",
    "logit = logit.fit(dirtyDataLogit[predictors], dirtyData[outcome])\n",
    "kFoldAccuracy = model_selection.cross_val_score(logit, dirtyDataLogit[predictors], dirtyDataLogit[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(logit, dirtyDataLogit[predictors], dirtyDataLogit[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(logit, dirtyDataLogit[predictors], dirtyDataLogit[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the Logistic regression is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the Logistic regression classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the Logistic regression classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the Non Linear SVC classifier is:\n",
      "[ 0.8358209   0.83        0.835       0.8241206   0.83919598  0.8241206\n",
      "  0.8241206   0.83417085  0.80904523  0.83417085] \n",
      "And their mean is:\n",
      "  0.828976561914\n",
      "\n",
      "The 10 Fold precision of the Non Linear SVC classifier is:\n",
      "[ 0.86614173  0.85271318  0.85384615  0.8515625   0.8907563   0.84615385\n",
      "  0.86290323  0.90350877  0.848       0.85384615] \n",
      "And their mean is:\n",
      "  0.862943186468\n",
      "\n",
      "The 10 Fold recall of the Non Linear SVC classifier is:\n",
      " [ 0.87301587  0.88        0.888       0.872       0.848       0.88        0.856\n",
      "  0.824       0.848       0.888     ] \n",
      "And their mean is:\n",
      "  0.865701587302\n"
     ]
    }
   ],
   "source": [
    "#3 Non Linear SVM with clean data\n",
    "\n",
    "cleanDataNLsvc = cleanData.drop(['state','fold','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "predictors = list(cleanDataNLsvc)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "NLsvc= NuSVC()\n",
    "\n",
    "NLsvc = NLsvc.fit(cleanDataNLsvc[predictors], cleanData[outcome])\n",
    "kFoldAccuracy = model_selection.cross_val_score(NLsvc, cleanDataNLsvc[predictors], cleanDataNLsvc[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(NLsvc, cleanDataNLsvc[predictors], cleanDataNLsvc[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(NLsvc, cleanDataNLsvc[predictors], cleanDataNLsvc[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the Non Linear SVC classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the Non Linear SVC classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the Non Linear SVC classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the Non Linear SVC classifier is:\n",
      "[ 0.8358209   0.83        0.835       0.8241206   0.83919598  0.81909548\n",
      "  0.82914573  0.83417085  0.81407035  0.83919598] \n",
      "And their mean is:\n",
      "  0.82998158704\n",
      "\n",
      "The 10 Fold precision of the Non Linear SVC classifier is:\n",
      "[ 0.86614173  0.85271318  0.85384615  0.8515625   0.8907563   0.83969466\n",
      "  0.8699187   0.90350877  0.85483871  0.86046512] \n",
      "And their mean is:\n",
      "  0.864344582051\n",
      "\n",
      "The 10 Fold recall of the Non Linear SVC classifier is:\n",
      " [ 0.87301587  0.88        0.888       0.872       0.848       0.88        0.856\n",
      "  0.824       0.848       0.888     ] \n",
      "And their mean is:\n",
      "  0.865701587302\n"
     ]
    }
   ],
   "source": [
    "#4 Non Linear SVM with full data\n",
    "dirtyDataNLsvc = dirtyData.drop(['ViolentCrimesPerPop'], axis=1)\n",
    "predictors = list(dirtyDataLogit)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "NLsvc= NuSVC()\n",
    "\n",
    "NLsvc = NLsvc.fit(dirtyDataNLsvc[predictors], dirtyData[outcome])\n",
    "kFoldAccuracy = model_selection.cross_val_score(NLsvc, dirtyDataNLsvc[predictors], dirtyDataNLsvc[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(NLsvc, dirtyDataNLsvc[predictors], dirtyDataNLsvc[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(NLsvc, dirtyDataNLsvc[predictors], dirtyDataNLsvc[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the Non Linear SVC classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the Non Linear SVC classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the Non Linear SVC classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.\tWhat method gives the best results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression has a better performance than Non Linear kernal of Support Vector Machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii.\tWhat feature(s) seem to be most consistently predictive of high crime rates? How reliable is this conclusion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High crime features: \n",
      "1: racepctblack\n",
      "2: MalePctDivorce\n",
      "3: PctIlleg\n",
      "4: TotalPctDiv\n",
      "5: racePctHisp\n",
      "6: FemalePctDiv\n",
      "7: PctPersDenseHous\n",
      "8: OtherPerCap\n",
      "9: HousVacant\n",
      "10: MedRentPctHousInc\n"
     ]
    }
   ],
   "source": [
    "highCrimeFeatures = []\n",
    "lowCrimeFeatures = []\n",
    "for i in range(0,len(predictors)-1):\n",
    "    info = []\n",
    "    info.append(abs(logit.coef_[0,i]))\n",
    "    info.append(predictors[i])\n",
    "    if(logit.coef_[0,i] > 0):\n",
    "        highCrimeFeatures.append(info)\n",
    "    else:\n",
    "        lowCrimeFeatures.append(info)\n",
    "\n",
    "highCrimeFeatures.sort(reverse=True)\n",
    "topTenHighCrimeFeatures = highCrimeFeatures[:10]\n",
    "\n",
    "print(\"High crime features: \")\n",
    "index = 1\n",
    "for i in topTenHighCrimeFeatures:\n",
    "    print(str(index) + \": \" + i[1])\n",
    "    index = index + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features involving divorce such as MalePctDivorce, FemalePctDiv and TotalPctDiv tend to repeat across all the models as an indicator of high crime. Also PctIlleg seems to be a good predictor of high crime. Features are not consistant across models hence are not very reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teams\n",
    "### a. Team of three people:\n",
    "\n",
    "#### ii.\tDevise a method to find the most useful threshold for dividing high crime areas from low crime areas (i.e., discretizing XXX to compute highCrime). Define clearly what you mean by “useful”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "cleanData = pd.read_csv(\"communities-crime-clean.csv\")\n",
    "threshold = np.arange(0,0.5,0.01)\n",
    "maxAccuracy = 0\n",
    "beatThreshold = 0\n",
    "maxAccuracy = []\n",
    "minMSE = []\n",
    "a = []\n",
    "for i in threshold:\n",
    "    cleanData['highCrime'] = 0\n",
    "    condition = cleanData['ViolentCrimesPerPop'] > i\n",
    "    cleanData.loc[condition, 'highCrime'] = 1\n",
    "    \n",
    "    cleanDataLogit = cleanData.drop(['fold','state','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "    outcome = 'highCrime'\n",
    "    predictors = list(cleanDataLogit)\n",
    "    predictors.remove(outcome)\n",
    "\n",
    "    logit = LogisticRegressionCV()\n",
    "    \n",
    "    kFoldAccuracy = model_selection.cross_val_score(logit, cleanDataLogit[predictors], cleanDataLogit[outcome], cv=10, scoring='accuracy')\n",
    "    maxAccuracy.append(np.max(abs(kFoldAccuracy)))\n",
    "    a.append(i)\n",
    "    \n",
    "    kFoldMSE = model_selection.cross_val_score(logit, cleanDataLogit[predictors], cleanDataLogit[outcome], cv=10, scoring='neg_mean_squared_error')\n",
    "    minMSE.append(np.min(abs(kFoldMSE)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY3z6/9m/a5qLTeEdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115a478d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a,maxAccuracy)\n",
    "plt.axis([0,0.6,0.8,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8lOW5+P/PlT2EJED2hCUJBBBkUcLqvqCgWLS1VetR\nq61oj9q9PXz7avvr+ba/c3psbU97jlWptbX1qEdbrYBUq7RuyBYUAoghISwJhJCd7Ov1/WMmOIRJ\n8kwy2SbX+/WaV2ae576fuW+GzJXnXkVVMcYYY7oKGuoCGGOMGZ4sQBhjjPHKAoQxxhivLEAYY4zx\nygKEMcYYryxAGGOM8cpRgBCRFSKSJyIFIrLWy/nbRSRXRPaKyPsiMq+3vCIyQUTeEJF898/x/qmS\nMcYYf+g1QIhIMPAosBKYBdwmIrO6JDsMXKaqc4AfAesc5F0LbFbVLGCz+7UxxphhwskdxCKgQFUL\nVbUFeB5Y7ZlAVd9X1Sr3y23ARAd5VwNPu58/DdzY92oYY4zxtxAHadKAIo/XxcDiHtJ/Efirg7xJ\nqlrifn4SSPJ2MRFZA6wBiIqKWjBz5kwHRTbGGNNp165d5aqa4Gs+JwHCMRG5AleAuNiXfKqqIuJ1\nzQ9VXYe7ySo7O1tzcnL6XU5jjBlNRORoX/I5aWI6DkzyeD3RfaxrAeYCTwKrVbXCQd5SEUlx500B\nTvlWdGOMMQPJSYDYCWSJSIaIhAG3Aus9E4jIZOAl4A5VPegw73rgLvfzu4BX+l4NY4wx/tZrE5Oq\ntonIg8DrQDDwlKruF5H73ecfB34AxAG/FhGANlXN7i6v+9I/AV4QkS8CR4HP+bluxhhj+kFG0nLf\n1gdhjDG+E5Fdqprtaz6bSW2MMcYrCxDGGGO8sgBhjDHGKwsQxhhjvLIAYYwxxisLEMYYY7yyAGGM\nMcYrCxDGGGO8sgBhjDHGKwsQxhhjvLIAYYwxxisLEMYYY7yyAGGMMcYrCxDGGGO8sgBhjDHGKwsQ\nxhhjvLIAYYwxxisLEMYYY7xyFCBEZIWI5IlIgYis9XJ+pohsFZFmEfmWx/EZIrLb43FaRL7mPvdD\nETnuce46/1XLGGNMf4X0lkBEgoFHgeVAMbBTRNar6kceySqBrwA3euZV1Txgvsd1jgMveyT5har+\nrF81MMYYMyCc3EEsAgpUtVBVW4DngdWeCVT1lKruBFp7uM5VwCFVPdrn0hpjjBk0TgJEGlDk8brY\nfcxXtwLPdTn2kIjkishTIjK+D9c0xhgzQAalk1pEwoBPAS96HH4MyMTVBFUCPNJN3jUikiMiOWVl\nZQNeVmOMMS5OAsRxYJLH64nuY75YCXygqqWdB1S1VFXbVbUD+A2upqxzqOo6Vc1W1eyEhAQf39YY\nY0xfOQkQO4EsEclw3wncCqz38X1uo0vzkoikeLy8Cdjn4zWNMcYMoF5HMalqm4g8CLwOBANPqep+\nEbnfff5xEUkGcoAYoMM9lHWWqp4WkShcI6Du63Lph0VkPqDAES/njTHGDCFR1aEug2PZ2dmak5Mz\n1MUwxpgRRUR2qWq2r/lsJrUxxhivLEAYY4zxygKEMcYYryxAGGOM8coChDHGGK8sQBhjjPHKAoQx\nxhivLEAYY4zxygKEMcYYryxAGGOM8coChDHGGK8sQBhjjPHKAoQxxhivLEAYY4zxygKEMcYYryxA\nGGOM8coChDHGGK8sQBhjjPHKAoQxxhivHAUIEVkhInkiUiAia72cnykiW0WkWUS+1eXcERHZKyK7\nRSTH4/gEEXlDRPLdP8f3vzrGGGP8pdcAISLBwKPASmAWcJuIzOqSrBL4CvCzbi5zharO77Jp9lpg\ns6pmAZvdr40xxgwTTu4gFgEFqlqoqi3A88BqzwSqekpVdwKtPrz3auBp9/OngRt9yGscqm9uo7qh\nZaiLYYwZgZwEiDSgyON1sfuYUwq8KSK7RGSNx/EkVS1xPz8JJHnLLCJrRCRHRHLKysp8eFsD8K0X\n9/CZx95HVYe6KMaYEWYwOqkvVtX5uJqoHhCRS7smUNe3l9dvMFVdp6rZqpqdkJAwwEUNLK3tHbx9\nsIxDZfXsPFI11MUxxowwTgLEcWCSx+uJ7mOOqOpx989TwMu4mqwASkUkBcD985TTaxpndhdV09DS\nDsCLOUW9pDbGmLM5CRA7gSwRyRCRMOBWYL2Ti4tIlIhEdz4HrgH2uU+vB+5yP78LeMWXggea7YUV\nVNQ1+/Wa7+WXIwLXzk7i1b0l1De3+fX6xpjA1muAUNU24EHgdeAA8IKq7heR+0XkfgARSRaRYuAb\nwPdEpFhEYnD1K7wnInuAHcCrqvqa+9I/AZaLSD5wtfv1qNTU2s7tT27n5se3UlLT6LfrbikoZ25a\nLF+6JJOGlnY27S3pPZMxxriFOEmkqpuATV2OPe7x/CSupqeuTgPzurlmBXCV45IGsOPVjbR1KIfL\n67nliW08e+9iJo4f069r1ja18mFRNfddmkn2lPFkxEfxp13FfDZ7Uu+ZjTEGm0k9LBRVNgDwvevP\no7qhhVue2HbmWF9tL6ykvUO5OCseEeHmBRPZfriSYxX9u64xZvSwADEMFFe5mpVWzU3l2XuXUN/S\nxuee2MqR8vo+X/O9gnIiQoO4cLJrgvqnL0xDBP60yzqrjTHOWIAYBoqqGggLDiIxOpzz02J59ktL\naG7r4HNPbOVQWV2frrmloJyF6ROICA0GICU2kounxfPnD47T0WFzIowxvXPUB2Fc9p+o4ev/u5tH\nPjufORNj/Xbd4spG0sZHEhQkAMxKjeG5e5dw+5PbWPnLd4kKCz4nzx1L0/nG8uler1d6uon8U3Xc\nvODsbqHPZk/iK899yNbCCi6aFu+38htjApMFCB+8tu8kB0vruPv3O/jzl5cxJS7KL9ctrmpg4vjI\ns47NSI7mhfuW8sy2Y7R1dJx1bt/xGh5/+xD/tHgyiTER51zvvfxyAC7OOjsIXDMriZiIEF7MKbIA\nYYzplQUIH2wvrGRK3BhON7Zy51OuIBE/Nrzf1y2qauTa1HPvSDITxvKDG7quiwhHyuu58pG3ePK9\nw3z3uvPOOb+loJwJUWGclxxz1vGI0GA+NT+VF3OK+b9NrcREhPa77MaYwGV9EA41tbazu6iaFbOT\n+e0XFlJ6uom7f7eTun5OPqtvbqOyvoVJEyJ7T+yWHh/FDfNSeWbbUarqz16IT1V5r6CcZVPjzjRZ\nebp5wSSa2zp4NdfmRBhjemYBwqEPjlXR0t7Bksw4Lpw8nl/ffiEflZzmy8/soqWto/cLdKOoyjXs\ndJKP8x7++fJpNLS087v3j5x1vOBUHadqm7kky3sT0ryJsWQljrWlN4wxvbIA4dC2wkqCBLLTXcNG\nr5yZxL9/eg7v5pfznT/t6fPIoOJK1xDXSRN8CxAzkqNZPiuJ3285fNZdzLvu/ofu+hhEhM9mT+SD\nY9UUnKrtU5mNMaODBQiHthdWcH5aLNEe7fafy57Et6+dwV92n+AXbx7s03U77yC6dlI78eAV0zjd\n1MYz246eObaloJz0uDE9zsS+6YKJjAkL5r4/7uLU6SbfC22MGRUsQDjQ1NrOh0XVLM6YcM65f758\nKp+5cCKPvXWIw32Y2FZU2UhkaDBxUWE+5503aRyXZMXz5LuHaWptp7W9g20OhrAmRIfzuy8spKSm\niVvWbfPr+k/GmMBhAcKB3UXVtLS5+h+6EhHWrpxJWEgQP339Y5+vXVzVwKQJkYic26HsxANXTKO8\nrpn/3VnEnqJq6lvau+1/8LQ4M44/fnERZbXN3PLENo5XW5AwxpzNAoQD2worEIHs9HPvIMD1F/l9\nl05l096T7Drq28Y8RVWN/VqYb3HGBBZMGc8Tbx/iH3mnEIGlmc7mOCyYMoE/fnERVQ0t3PLE1n6v\n/2SMCSwWIBzYXljJrJQYYiO7nzfwpUsySIgO5983HXC8vaeqUlzZwKQ+9D90EhEevGIaJ2qaePLd\nw8xNiyV2jPP5DRdMHs+zX1pCbVMbt/Rz/SdjTGCxANGL5rZ2PjhW5bV5yVNUeAhfv3o6OUer+NtH\npY6ufbqxjdrmNp9HMHV1+YwEZqfG0NzW0acZ0nMmxvLsvYtpbG3nzqd22P7VxhjAAkSv9hTV0NzW\n4bWDuqvPZU9kakIU//HXj2lt731uRH9GMHkSEb5yVRYAV52X2KdrzE6N5StXZXGssoGyWv/ubGeM\nGZksQPSis/9hkYMAERIcxNqV51FYXs//7ux9Ilpnm39/NwcCuHZ2Mu+vvZIFU3ovZ3emJowFoNCa\nmYwxWIDo1fbDFcxMjmHcGGfDUK8+L5FF6RP4zzcP9roMR+c+EP1tYuqUOq5/dyIZ8a7FB/syXNcY\nE3gcBQgRWSEieSJSICJrvZyfKSJbRaRZRL7lcXySiPxDRD4Skf0i8lWPcz8UkeMistv9uM4/VfKf\nlrYOdh2tYkmm87/KRYTvXn8e5XUtrHunsMe0RVUNxESE9Nj5PZhSx0USFhI0IAGirLbZ+jaMGWF6\nDRAiEgw8CqwEZgG3iUjXJUYrga8AP+tyvA34pqrOApYAD3TJ+wtVne9+bGKYyS2upqm1g8UZPXdQ\ndzV/0jiun5vCb94p7HGmclFlg1+al/wlOEhIjxvj9wCx/0QNi//tTX7yV9/niRhjho6TO4hFQIGq\nFqpqC/A8sNozgaqeUtWdQGuX4yWq+oH7eS1wAEjzS8kHwbbCCgBHHdRdfWP5dBpb29nQw6qpxVWN\nPq3iOhjS46L8HiDePlhGh8IT7xTy5Ls931UZY4YPJwEiDfDscS2mD1/yIpIOXABs9zj8kIjkishT\nIjK+m3xrRCRHRHLKysp8fdt+2X64kpnJ0YzvwzIYUxPGMiVuDFsPVXg9r6quADGM7iAAMhKiOFpR\nT7sftyXdXlhJZkIU181J5sevHuDlD4v9dm1jzMAZlE5qERkL/Bn4mqqedh9+DMgE5gMlwCPe8qrq\nOlXNVtXshISEwSguAK3tHeQcqerT3UOnpZlxbD9c4fXLtryuhcbW9n4PcfW3zPgoWtuV41X+WXqj\nrb2DnCOVLJsaxy9umc/SzDi+/WIub+Wd8sv1jTEDx0mAOA5M8ng90X3MEREJxRUc/kdVX+o8rqql\nqtquqh3Ab3A1ZQ0bucU1NLa29zpBridLp8ZR29TG/hM155wr7twHwk8jmPwlI75zqGudX66378Rp\n6lvaWZwRR3hIME/cuYDpSdF8+ZkP+PCYb8uSGGMGl5MAsRPIEpEMEQkDbgXWO7m4uFag+y1wQFV/\n3uVcisfLm4B9zoo8ODr7H5zMf+jOUndw8dbMVOTnIa7+4u+hrts7+3HcI8FiIkL5/T0LiY8O457f\n76TglH8CkTHG/3oNEKraBjwIvI6rk/kFVd0vIveLyP0AIpIsIsXAN4DviUixiMQAFwF3AFd6Gc76\nsIjsFZFc4Arg6/6vXt9tP1zJ9KSxxPVjz+nEmAimJkSxtdBLgHBPkkvr59wFf4sfG0Z0eIjfAsS2\nwgoyE6JIjI44cywxOoI/3rOYIBG+/MwuG/5qzDAV4iSRewjqpi7HHvd4fhJX01NX7wFe17FW1Tuc\nF3NwNbS0seNwBbdkT+o9cS+WTo3jpQ+O09reQWjwJ/G4uKqBuKgwosIdfQSDRkTISPDPSKb2DiXn\nSBWr5qWecy49PorvrJjBv/x5L3uP1zB34rh+v58xxr9sJrUXbx44RVNrB9fNSek9cS+WTY2noaWd\n3OKz+yGKqxqZOMyalzplxPsnQHx04jS1zW3dTjS8dnYyIUHCxh6GAhtjho4FCC827DlBUkw4C7vZ\n/8EXS870Q5Sfddw1SW54NS91So+L4nh1I02t7f26zifzSLx39I8bE8YlWfG8mltizUzGDEMWILo4\n3dTK23llXD8nlaCgvu3y5mlCVBgzk6PP6odo71COVw+/ORCdMhOiUIVj/dxAaPvhCtLjxpAcG9Ft\nmlVzUzle3cgHx6r79V7GGP8bXg3gw8Df9pfS0t7Bqnn9b17qtHRqHM9uP0ZzWzvhIcGcqm2itV2H\n3SzqTp0jmQrL6pmeFN2na7R3KDsOV/baTLd8dhJhLwWxMfcEC6Z4nSt5Rmt7B6WnmyipaeJEdSMl\nNU2crGnyeqcTFR7CN6+Zzpgw+y9uTF/Zb08XG/acIG1cJBdM8l+n6dLMOH635QgfHqtmSWYcRZXu\nIa7D9A4i3Q9DXQ+UnOZ0U9uZ4a3diYkI5bIZCWzaW8L3r5/V7V3byx8W8+0Xc2nrMukwOjyEMeHB\nZx1ThVO1zSTFhLPm0ql9roMxo50FCA+V9S1sKSjnS5dk4prC4R+LM+MIEtd8CFeA8M9GQQMlJiKU\n+LHhHO7HZLnthyuB7vsfPN0wL5U3Pipl55FKFnuZmFjX3MaPNx7gvJQYbl88mZRxkaTGRpAcG0F0\nhPeVcO/47XbWvXOYO5emExEa7DWNMaZn1gfh4bV9J2nrUFbN9V/zEkBsZCizU2PPTJgrrmpEBNKG\naYAA15IbR8r73gexrbCCyRPGONqj4qqZiUSEBnU7mmndO4VU1Lfw4xvP59ZFk7lsegJZSdHdBgeA\nB6+YRnldM8/vONbnOhgz2lmA8LAx9wSZ8VHMTo3x+7WXTo3jw6IqGlvaKapqICk6gvCQ4fuXbUZ8\nVJ93luvoUNfdgMNZ6FHhIVw1M4lNe0to67JV66naJp58t5Dr56Qwz4dmv8WZcSxKn8AT7xTS3Na/\n0VjGjFYWINxOnW5ia2EFq+am+LV5qdPSqXG0tiu7jlYN6yGunTISoiiva+Z0U2vvibvIK62luqHV\na3NRd1bNTaGivoVthZVnHf/V5nxa2jr49rUzfC7Hg1dOo6SmiZc+cLx0mDHGgwUIt017S1B1tYcP\nhIXpEwgOEt4/VO7eB2J4dlB3So9zdVQf6cNdRF/20bhiZiJRYcFszD1x5lhhWR3P7Sji84snn+k4\n98UlWfHMmzSOX79VcM6dyWBpaeuguKqBXUcr2Zh7giffLeRXm/NpbLG7GjP8WSe128bcEmYkRZPV\nx2GdvRkbHsLcibG8m19OSU0jk4b5HURmwicjmXxdBmN7YSVp4yJ9CoIRocEsn5XEa/tP8qMbzyc0\nOIifvp5HREgQD12Z5dP7dxIRHrpiGl/6Qw6v7D7BZxZ4Ww1m4Dz03Ids2HPC67m4sWHcvnjKoJbH\nGF/ZHQRworqRnKNV3ODHuQ/eLJsax97jNXQow2qrUW8mTxiDiGsuhC86OpQdRyr7tEz6qrmpVDe0\n8l5BOR8cq+Kv+05y76WZJET3fcHEq85L5LyUGB59q8CvmyD1praplU17S7hsegL/8Zk5/P7uhbz2\ntUvY/YPlTE2IYuMeW17EDH8WIIBX3aNnVs0dmOalTksz4888nzhMJ8l1iggNJm1cpM9zIfJP1VFZ\n39Lr/AdvLpkeT3RECBv3lPCTv35M/Ngw7r0k0+freBIRHrxiGoVl9fx13+B9Ke84XEl7h3LfpZnc\nsnAyl89IZGZyDOPGhLFqbirbDlf0uF+5McOBBQhgQ+4J5qTF9qmd2xcLpownNNjVAT5cJ8l5yoiP\n4kiFbwFi+2FX/8MSB/MfugoPCeba2cn8Zfdxdhyu5KtXZflltduV5yczLXEs//33AjoG6S7ivYJy\nwkOCuNDL7PAb5qWg6ur3MmY4G/UB4kh5PbnFNQPevAQQGRbMBZPHExwkpPSwPtFwkRkfxeGyep8W\n0tt6qILU2Ig+LyOyam4K7R1KetwYbl00uU/X6CooSHjgiql8fLKWzR8Pzlan7xdUsDB9gtdJetMS\no5mZHM0GW8XWDHOjPkC8vv8kANcPcPNSp7uXpXPHkimEBA//f/qM+Chqm9sor2txlL64qoE3D5Ry\n9aykPg8VvmhaPCtmJ/PjG+ectX9Gf90wN5XJE8aw7p1Dfrtmd07VNpFXWstF0+K7TXPDvFR2Ha3i\neLV/9v42ZiAM/2+pAbbraBXpcWMGbWe3lXNS+OGnZg/Ke/WXr2sy/fffCxCEL1/e9/WPQoODePyO\nBVyc1f2Xa1+EBAdxy8JJ7DxSdWY/8IHSOWP+4p4ChPsPkldzvY9yMmY4GPUBYk9xtU8zdEeTzPix\nAI7WZDpaUc+Lu4r5/OLJpMQOzw74T76UB7Zp5738cmIjQ5nVw4z8yXFjmDcxlg02mskMY44ChIis\nEJE8ESkQkbVezs8Uka0i0iwi33KSV0QmiMgbIpLv/tnzWs8D4GRNE6Wnm5lvAcKrtPGRhAaLoyU3\nfrk5n5Ag4Z/7cfcw0Dq/lAdyBztVZUtBOcumxhHcy34iq+amsvd4TZ8mIxozGHoNECISDDwKrARm\nAbeJyKwuySqBrwA/8yHvWmCzqmYBm92vB9XuItcmNXYH4V1wkDAlztVR3ZNDZXX85cPj3Ll0Cokx\nw7vz/YZ5A/ulfKSigRM1TSzroXmp0/XuRSE3WjOTGaac3EEsAgpUtVBVW4DngdWeCVT1lKruBLou\n3NNT3tXA0+7nTwM39rEOfba7qJrQYGFWiv8X5wsUToa6/vLNfCJCg7nvsuF799CpcwOjvnwpt7Z3\n8PO/5ZFb3P3ud1sKXFvL9tT/0Cl1XCTZU8ZbM5MZtpwEiDSgyON1sfuYEz3lTVLVzt+Mk0CStwuI\nyBoRyRGRnLKyModv68yeomrOS4mx/QJ6kBkfxZGKhm5nIeedrGVD7gnuWpZO/Ni+z3geLKnjIlmY\n7vuXcnuH8o0X9vCrvxfw7Rdzu51PsaWgnNTYCNLjnM1zuWFeKnmltRwsrfWpPMYMhmHRSa2ugfZe\nf+NUdZ2qZqtqdkJCgt/es71D2Xu8hnk+rjM02mTER9HS1sGJboZj/uebB4kKC2FNP2c8D6ZVc337\nUlZVvv/KPjbsOcFl0xPIK63lVS+T3No7lK2FFVw0Ld7xMN+Vc5IJEtjYzZpNxgwlJwHiODDJ4/VE\n9zEnespbKiIpAO6fgzODye1QWR11zW3W/9CLjB6Guu4/UcNf953knovSGR8VNthF6zNfv5Qffj2P\nZ7cf48uXT+V3X1jIjKRofvHmwXNWiP3oxGmqG1p7nP/QVWJ0BEsy49iYW+LThERjBoOTALETyBKR\nDBEJA24F1ju8fk951wN3uZ/fBbzivNj919lBbSOYetYZILYWVlBU2UBT6yfLVP/ijXyiI0L44gi6\newDXl/LSqXFscPCl/Ou3CnjsrUPcvngy37l2BkFBwteXZ1FYVs8ru88OMFsOufoflk3zbZmRG+al\nUlhez/4Tp32riDEDrNcAoaptwIPA68AB4AVV3S8i94vI/QAikiwixcA3gO+JSLGIxHSX133pnwDL\nRSQfuNr9etDsKaomOjyEzAFef2mkS4gOJy4qjMfeOsQlD/+Dmd9/jbk/fJ0rH3mLNw+Ucu8lmcRG\ndr/153C1am4qh3v5Un5m21Eefi2P1fNT+dHq8880G107O5nZqTH8cnM+rR53EVsKypmeNJbEaN9G\ncq2YnUxIkLBhAEYzFZbV8dXnP6Suuc3v1zaBz9FKaKq6CdjU5djjHs9P4mo+cpTXfbwCuMqXwvrT\n7qJq5k6KJaiXseqjnYiw4aGLyTtZS1ltM2V1za6ftc2clxzD3RelD3UR+2TF7GS+/5d9bMg9wflp\nseecfzGniO+/so+rZibys8/OO+v/iYjwzWumc8/vc/jTrmJuWzSZptZ2dh6p5LY+rB81PiqMS6cn\n8Oy2Y6yYncwFk/03JejfNn3MmwdKuXhaPJ/NntR7BmM8jMoNg5pa2/n4ZC33XzaymkaGSuq4SFIH\naSmSwTI+KoyLs+LZuKeEtStmnrk7UFUe/UcBP/vbQS6eFs+jt1/odU2oK2YkMn/SOP5rcz6fvjCN\nD45V0dTa4Wh4qzc/uvF8blu3jTt+u4Pf372Q7HTfl0vvak9RNW8eKAVcG2JZgDC+GhajmAbb/hM1\ntHeojWAa5W6Ym8rx6kY+dPdHtbV38N2X9/Gzvx3kpgvSeOoLC7sdAi0ifOuaGZyoaeL5HUW8X1BB\ncJCwyIdtVj2ljYvkhfuWkhgdzp1P7TiznlN//PyNg4wbE8odS6awpaCcqnpniy4a02lUBojdRTWA\ndVCPdstnJxEWHMSGPSdoaGljzR938dyOYzxwxVR+/rl5hIX0/Otx0bQ4FmVM4L//UcDmj08xf9I4\noiP63h+THBvB8/ctIW1cJHf/fgfv5Zf3+Vq7jlby9sEy7rt0KrcsnERbh/Kae+ViY5wapQGimtTY\niGG/LIQZWDERoVw+I4GNuSXcum4bb+Wd4sc3ns+3r53paB6DiPDN5dMpq23mQMlpLprq+yZJXSVG\nR/D8miWkx0Vxz9M7+Ueea/S3qlLX3MaR8np2Ha2k4FTPczh+/sZB4seGcdeyKcxOjSEjPsqW9DA+\nG5V9EHuKbAVX47JqXip/+6iUuqY21t2RzdWzvE7o79bizDguyYrn3fxyn+Y/9CRubDjP3buEO57a\nzpo/5JAYHUF5XTPNbZ+MmBKBn948j5sXnDs2ZFthBVsKKvje9ecxJsz1K75qbgqP/qOAstrmfu3x\nbUaXURcgKutbOFbZwOcX+2e3MjOyXTMriXsuymD1/NQ+/9Hw/90wiz9uPep1e9G+Gh8Vxv98aQn/\n8drHNLW0Ex8dTvzYMOKiwokbG8Zv3zvMt/+0h7b2jrN23lNVfv63gyRGh/NPS6acOb5qbir/9fcC\nXttXwh1L0/1WThPYRl2A2GMT5IyHiNBgfnBD18WJfTMtMZp/XX2+n0r0idjIUP7tpjlezy3JjOP+\nZ3ax9qW9tHYod7iDwZaCCnYcqeRfPzX7rA72GcnRTE8ay4Y9FiCMc6OuD2J3UTVBAnO8jH03ZqSI\nCA3miTsWcPV5iXz/L/v43ZbDqCqPvJFHamwEty46d0jrqrmp7DxaycmapiEosRmJRl2A2FNcTVZi\nNFHho+7myQSY8JBgfn37Aq6dncS/bviIh577kA+PVfPglVmEh5w7PHfV3BRU8brQoDHejKoAoars\nKaq25iUTMMJCgvjvz1/I9XNS2JhbwqQJkXw22+uiBmQmjGVWSoyNZjKOjao/o49VNlDV0GojmExA\nCQ0O4pc5ev79AAATPUlEQVS3zmd6UjRLMid4nfndadW8FB5+LY/iqgYmjne2Z4UZvUbVHcQnW4xa\n/4MJLCHBQXz16iwWZ/Y8F2PVnFQAXh3AfblN4Bh1ASIiNIgZSdFDXRRjhsTkuDHMmxjLRgsQxoFR\nFSD2FFUzJy2WkB5uwY0JdDfMS2Xv8RqOeNkEyhhPo6YPorW9g30nTnOnx+QhY0aj6+ak8ONXD/DE\nO4dYPT+N8WPCGB8VyvgxYYQGB9HeoVQ3tFDV0EJlfSuV9S20tncwISrszGPcmFCvI6VMYBk1AeJw\neT0tbR1e1/43ZjRJHRfJsqlxPLejiOd2FJ11bkxYMI2t7TjZ/TQmIoR///Rcrp+bMkAlNUNt1ASI\nzg3qs5LGDnFJjBl6T31hIUcq6qmsb6GqvpXKhhaq6luoaWxlbHgIE6LCGB8VxgT33UVocBBV9Z/c\nVVQ1tLB+9wn+dcN+rpyZSGSY3U0EolEUIOoIEpiaYAHCmIjQYGYmx/TrGosyJvDZx7fyu/cP88+X\nT/NTycxw4qi3VkRWiEieiBSIyFov50VEfuU+nysiF7qPzxCR3R6P0yLyNfe5H4rIcY9z1/m3amfL\nL61lSlxUtxvAGGN8szB9AlfNTOTxtw5R09A61MUxA6DXACEiwcCjwEpgFnCbiHRd3WwlkOV+rAEe\nA1DVPFWdr6rzgQVAA/CyR75fdJ537109YA6W1pKVaHcPxvjTt1fMoLa5jcfePjTURTEDwEkT0yKg\nQFULAUTkeWA18JFHmtXAH1RVgW0iMk5EUlTVc7D1VcAhVT3qp7I71tzWzpGKBlaeb51pxvjTzOQY\nbpqfxu+2HOYLy9JJjnW+CVdNYyv/s/0op043U9XQQlVD65nRU/MnjeenN8+1O/4h5qSJKQ3wHOpQ\n7D7ma5pbgee6HHvI3ST1lIh4XUxfRNaISI6I5JSVlTko7rkOl9fT3qHWQW3MAPj68ul0qPLLzfmO\n85SebuKWJ7by8Gt5vPRBMR8eq6amoYXxY8KYlRLDhj0nePDZD2lt7+j9YmbADEontYiEAZ8C/o/H\n4ceAHwHq/vkIcE/XvKq6DlgHkJ2d7WDw3bkOltYBMN1mUBvjd5MmjOH2xVP447aj3HtJBpm9DAQp\nLKvjjt/uoLqhhWe+uJiLs87die8PW4/wg1f2840X9vCft8wnOKj3LWCN/zm5gzgOeC4uP9F9zJc0\nK4EPVLW084Cqlqpqu6p2AL/B1ZQ1IPJLawkOEjITogbqLYwZ1R64YhrhIUE88reDPabbXVTNzY9v\npam1nefXLPUaHADuXJrO2pUz2bDnBP/npVw6Ovr0t6HpJycBYieQJSIZ7juBW4H1XdKsB+50j2Za\nAtR06X+4jS7NSyLi2SFwE7DP59I7dLC0lilxY2zmpzEDJCE6nC9dksmre0vILa72mubtg2V8/jfb\niAoP5k9fXsaciT1PWr3/sql85cppvJBTzP/d+BHqZPae8atem5hUtU1EHgReB4KBp1R1v4jc7z7/\nOLAJuA4owDVS6e7O/CISBSwH7uty6YdFZD6uJqYjXs77TX5pnTUvGTPA7r0kgz9uPcL3X9nPp+al\nnnWuuqGFx946RFZSNE/fvZDEGGed2V9fPp36lnZ++95hxoQF850VMweg5KY7jvog3ENQN3U59rjH\ncwUe6CZvPXDOGsSqeodPJe2jptZ2jlTUs8qWAzBmQEVHhPIvK2by3Zf3ntn73dNF0+J47J8WEBMR\n6viaIsL3rj+PxtZ2fv3WIaYnRXPjBV3Hv5iBEvAzqQvL6ulQyLI7CGMG3K2LJnPDvFTavPQZxESE\nIOJ7Z7OI8OPV55NbXM0jb+Rx/dyUHjdFMv4T8P/K+adcazBZE5MxgyMqPITYyNBzHn0JDp2CgoRv\nLJ9OUWUjL+YU+7G0picBHyAOltYSEiRkxNsIJmNGsitmJHLB5HH819/zaWptH+rijAqjIEDUkR4f\nRVhIwFfVmIAmInxz+QxKapp4fsexoS7OqBDw35r5pbVMtxnUxgSEi6bFsThjAo++dYjGFruLGGgB\nHSCaWts5WtlAVqL1PxgTCESEb14zg7LaZp7ZNujLuo06AR0gCk7VoWod1MYEkkUZE7gkK57H3j5E\nXXPbUBcnoAV0gPhkBJM1MRkTSL55zQwq61t4+v0jQ12UgBbQAeJgaR2hwUK6jWAyJqDMnzSOq2Ym\n8sTbh6hptM2KBkpAB4j80loy4qNsUo0xAejry6dzuqmNX76Zz0cnTp/1OFBympY2Wyq8vwJ6JvXB\n0rpeFwQzxoxM56fFct2cZJ7acpinthw+5/znF0/m326aMwQlCxwBGyAaW9opqmrgMxdOHOqiGGMG\nyL9/ei6r56fRdaHXTXtL+N+dRXzp4t73pzDdC9gA8ckIJvvPYUygio0M5drZyeccXzBlPG98VMov\n3sznv267YAhKFhgCtnH+YKlrBJMt0mfM6JMQHc49F6ezYc8J9p+oGerijFiBGyBO1RIWHER63Jih\nLooxZgisuXQqsZGh/Oz1vKEuyogVsAEiv7SOzIQoQmwEkzGjUmxkKPdfNpV/5JWx80jlUBdnRArY\nb8+DpbXWvGTMKPeFZekkRIfz8Gsf25alfRCQAaK+uY3iqkamJ1oHtTGjWWRYMF+5cho7j1Tx1sGy\noS7OiOMoQIjIChHJE5ECEVnr5byIyK/c53NF5EKPc0dEZK+I7BaRHI/jE0TkDRHJd/8c758quUYw\ngXVQG2PgloWTmTQhkp++lkeHl53uTPd6DRAiEgw8CqwEZgG3icisLslWAlnuxxrgsS7nr1DV+aqa\n7XFsLbBZVbOAze7XftE5gsmGuBpjwkKC+Mby6XxUcppX95YMdXFGFCd3EIuAAlUtVNUW4HlgdZc0\nq4E/qMs2YJyIpPRy3dXA0+7nTwM3+lDuHuWfqiMsJIgpcbYGkzEGPjUvjRlJ0fz8jYO0ttsSHE45\nCRBpQJHH62L3MadpFHhTRHaJyBqPNEmq2hnOTwJJ3t5cRNaISI6I5JSVOWtDPFhay9SEsQQH9X0P\nXGNM4AgOEr517Qxqm9o4Ul4/1MUZMQZjJvXFqnpcRBKBN0TkY1V9xzOBqqqIeG0cVNV1wDqA7Oxs\nRw2I+aV1LEz3W5eGMSYAXH1eIhd/5woiw4KHuigjhpM7iOPAJI/XE93HHKVR1c6fp4CXcTVZAZR2\nNkO5f57ytfDe1Da1cry6kenJ1kFtjPmEiFhw8JGTALETyBKRDBEJA24F1ndJsx640z2aaQlQo6ol\nIhIlItEAIhIFXAPs88hzl/v5XcAr/awL4FrBFWCGjWAyxph+6bWJSVXbRORB4HUgGHhKVfeLyP3u\n848Dm4DrgAKgAbjbnT0JeFlEOt/rWVV9zX3uJ8ALIvJF4CjwOX9U6JMRTBYgjDGmPxz1QajqJlxB\nwPPY4x7PFXjAS75CYF4316wArvKlsE4cLK1lTFgwaeMi/X1pY4wZVQJuJnXnEhtBNoLJGGP6JeAC\nRN7JOltiwxhj/CCgAkRlfQvldc3MsBFMxhjTbwEVIKyD2hhj/CcgA4TdQRhjTP8FVIDIO1lLTEQI\nidHhQ10UY4wZ8QIqQOSX1jEjORr3vAtjjDH9EDABQlXJK621/gdjjPGTgAkQp2qbqWlstQBhjDF+\nEjABIu+kjWAyxhh/CpgAYbvIGWOMfwVUgIgfG07cWBvBZIwx/hAwASKvtM7uHowxxo8CIkB0dCgF\nNoLJGGP8KiACxPHqRupb2m0GtTHG+FFABAjroDbGGP8LiACR5w4QWdbEZIwxfhMQASK/tI7U2Ahi\nIkKHuijGGBMwHAUIEVkhInkiUiAia72cFxH5lft8rohc6D4+SUT+ISIfich+EfmqR54fishxEdnt\nflzX10rknaxluvU/GGOMX/UaIEQkGHgUWAnMAm4TkVldkq0EstyPNcBj7uNtwDdVdRawBHigS95f\nqOp89+OsPa+damvvoKCszkYwGWOMnzm5g1gEFKhqoaq2AM8Dq7ukWQ38QV22AeNEJEVVS1T1AwBV\nrQUOAGl+LD9HKxtoaeuwAGGMMX7mJECkAUUer4s590u+1zQikg5cAGz3OPyQu0nqKREZ77DMZ8nv\n3CTIAoQxxvjVoHRSi8hY4M/A11T1tPvwY0AmMB8oAR7pJu8aEckRkZyysrJzzuedrEMEpiXaEFdj\njPEnJwHiODDJ4/VE9zFHaUQkFFdw+B9VfakzgaqWqmq7qnYAv8HVlHUOVV2nqtmqmp2QkHDO+YOl\ntUyeMIbIsGAHVTHGGOOUkwCxE8gSkQwRCQNuBdZ3SbMeuNM9mmkJUKOqJeLa2u23wAFV/blnBhFJ\n8Xh5E7CvLxWwTYKMMWZghPSWQFXbRORB4HUgGHhKVfeLyP3u848Dm4DrgAKgAbjbnf0i4A5gr4js\ndh/7rnvE0sMiMh9Q4Ahwn6+Fb25r50h5PdfOTvI1qzHGmF70GiAA3F/om7oce9zjuQIPeMn3HuB1\ng2hVvcOnknpRcKqOtg61OwhjjBkAI3om9eYDpwBYlDFhiEtijDGBZ0QHiFdzS1iYPp6U2MihLoox\nxgScERsg8ktrySutZdXc1KEuijHGBKQRGyA25pYgAivPTx7qohhjTEAakQFCVdmYe4JF6RNIjIkY\n6uIYY0xAGpEBIq+0lkNl9ayaZ81LxhgzUEZkgNi4p4QggRWzrXnJGGMGyogLEKrKq3tLWDo1joTo\n8KEujjHGBKwRFyA+KjnN4fJ6rp9jzUvGGDOQRlyA2JhbQnCQsMJGLxljzIAacQHi1dwSlk2NY0JU\n2FAXxRhjAtqIChCNLe0cq2zgBpscZ4wxA25EBYiaxlZCgoRrbPVWY4wZcCMqQFQ3tnJxVjzjxljz\nkjHGDLQRFSBa2zts7SVjjBkkIypACLB8ljUvGWPMYBhRASI6IoTYyNChLoYxxowKIypApIyzfR+M\nMWawjKgAERY8ooprjDEjmqNvXBFZISJ5IlIgImu9nBcR+ZX7fK6IXNhbXhGZICJviEi+++d4/1TJ\nGGOMP/QaIEQkGHgUWAnMAm4TkVldkq0EstyPNcBjDvKuBTarahaw2f3aGGPMMOHkDmIRUKCqhara\nAjwPrO6SZjXwB3XZBowTkZRe8q4GnnY/fxq4sZ91McYY40chDtKkAUUer4uBxQ7SpPWSN0lVS9zP\nTwJex6+KyBpcdyUAzSKyz0GZR6p4oHyoCzGAArl+gVw3sPqNdDP6kslJgBhwqqoiot2cWwesAxCR\nHFXNHtTCDSKr38gVyHUDq99IJyI5fcnnpInpODDJ4/VE9zEnaXrKW+puhsL985TzYhtjjBloTgLE\nTiBLRDJEJAy4FVjfJc164E73aKYlQI27+ainvOuBu9zP7wJe6WddjDHG+FGvTUyq2iYiDwKvA8HA\nU6q6X0Tud59/HNgEXAcUAA3A3T3ldV/6J8ALIvJF4CjwOQflXedL5UYgq9/IFch1A6vfSNen+omq\n16Z/Y4wxo5xNTTbGGOOVBQhjjDFeDcsA0Z+lPYY7B3WbKSJbRaRZRL41FGXsDwf1u939me0VkfdF\nZN5QlLOvHNRvtbt+u0UkR0QuHopy9lVv9fNIt1BE2kTk5sEsX385+PwuF5Ea9+e3W0R+MBTl7Asn\nn527frtFZL+IvN3rRVV1WD1wdWYfAjKBMGAPMKtLmuuAv+LaImIJsH2oy+3HuiUCC4H/H/jWUJd5\nAOq3DBjvfr5ypHx2PtRvLJ/07c0FPh7qcvuzfh7p/o5rcMrNQ11uP39+lwMbh7qsA1S3ccBHwGT3\n68Terjsc7yD6s7THcNdr3VT1lKruBFqHooD95KR+76tqlfvlNlxzY0YKJ/WrU/dvHxAFjKRRIE5+\n9wAeAv7MyJu75LR+I5GTun0eeElVj4Hru6a3iw7HANHdsh2+phmORmq5nfK1fl/EdSc4Ujiqn4jc\nJCIfA68C9wxS2fyh1/qJSBpwE+4FOUcYp/8/l7mbCf8qIrMHp2j95qRu04HxIvKWiOwSkTt7u+iw\nWGrDjD4icgWuADGi2uidUNWXgZdF5FLgR8DVQ1wkf/pP4F9UtUNEhrosA+EDXE0wdSJyHfAXXKtU\nB4IQYAFwFRAJbBWRbap6sKcMw01/lvYY7kZquZ1yVD8RmQs8CaxU1YpBKps/+PT5qeo7IpIpIvGq\nOhIWgnNSv2zgeXdwiAeuE5E2Vf3L4BSxX3qtn6qe9ni+SUR+PUI+PyefXTFQoar1QL2IvAPMA7oN\nEEPeueKlsyUEKAQy+KSzZXaXNNdzdif1jqEut7/q5pH2h4y8Tmonn91kXDPulw11eQeoftP4pJP6\nQvcvqQx12f1Vvy7pf8/I6qR28vkle3x+i4BjI+Hzc1i383DtvRMCjAH2Aef3dN1hdweh/VjaY7hz\nUjcRSQZygBigQ0S+hms0wuluLzxMOPzsfgDEAb92/xXapiNkFU2H9fsMrnXJWoFG4BZ1/3YOdw7r\nN2I5rN/NwJdFpA3X53frSPj8nNRNVQ+IyGtALtABPKmqPW6fYEttGGOM8Wo4jmIyxhgzDFiAMMYY\n45UFCGOMMV5ZgDDGGOOVBQhjjDFeWYAwxhjjlQUIY4wxXv0/+Xzf8nruuI8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115a470f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a,minMSE)\n",
    "plt.axis([0,0.6,0,0.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the optimum threshold value we plotted the thresholds vs MSE and threshold vs Accuracy. We choose threshold as 0.09 as it minimises the mean squared error(MSE) and accuracy compared to the earlier threshold. We think 0.09 is the most useful threshold as it minimises MSE while correctly classifying the violent crimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii.\tShow CV results for both the clean and full datasets for at least three different classification methods above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the decision tree classifier is:\n",
      "[ 0.80099502  0.77        0.725       0.75879397  0.71859296  0.73869347\n",
      "  0.83919598  0.75376884  0.73366834  0.75376884] \n",
      "And their mean is:\n",
      "  0.759247743694\n",
      "\n",
      "The 10 Fold precision of the decision tree classifier is:\n",
      "[ 0.83739837  0.8015873   0.80165289  0.796875    0.792       0.81355932\n",
      "  0.86290323  0.82758621  0.78688525  0.77692308] \n",
      "And their mean is:\n",
      "  0.809737064569\n",
      "\n",
      "The 10 Fold recall of the decision tree classifier is:\n",
      " [ 0.81746032  0.808       0.76        0.84        0.752       0.768       0.848\n",
      "  0.776       0.776       0.808     ] \n",
      "And their mean is:\n",
      "  0.795346031746\n"
     ]
    }
   ],
   "source": [
    "cleanData = pd.read_csv(\"communities-crime-clean.csv\")\n",
    "cleanData['highCrime'] = 0\n",
    "condition = cleanData['ViolentCrimesPerPop'] > thresh\n",
    "cleanData.loc[condition, 'highCrime'] = 1\n",
    "\n",
    "cleanDataLogit = cleanData.drop(['fold','state','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "outcome = 'highCrime'\n",
    "predictors = list(cleanDataLogit)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "decisionTree = tree.DecisionTreeClassifier()\n",
    "\n",
    "kFoldAccuracy = model_selection.cross_val_score(decisionTree, cleanDataDT[predictors], cleanDataDT[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(decisionTree, cleanDataDT[predictors], cleanDataDT[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(decisionTree, cleanDataDT[predictors], cleanDataDT[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the decision tree classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the decision tree classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the decision tree classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the naive baye's classifier is:\n",
      "[ 0.79        0.77        0.755       0.75        0.76        0.79396985\n",
      "  0.81407035  0.73869347  0.76884422  0.74242424] \n",
      "And their mean is:\n",
      "  0.768300213187\n",
      "\n",
      "The 10 Fold precision of the naive baye's classifier is:\n",
      "[ 0.95918367  0.90566038  0.93684211  0.91        0.95652174  0.95\n",
      "  0.98958333  0.92473118  0.92079208  0.91666667] \n",
      "And their mean is:\n",
      "  0.936998115723\n",
      "\n",
      "The 10 Fold recall of the naive baye's classifier is:\n",
      " [ 0.71212121  0.72727273  0.67424242  0.68939394  0.66666667  0.72519084\n",
      "  0.72519084  0.65648855  0.70992366  0.67175573] \n",
      "And their mean is:\n",
      "  0.695824658802\n"
     ]
    }
   ],
   "source": [
    "cleanDataNB = cleanData.drop(['state','fold','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "NB = GaussianNB()\n",
    "\n",
    "NB = NB.fit(cleanDataNB[predictors], cleanData[outcome])\n",
    "kFoldAccuracy = model_selection.cross_val_score(NB, cleanDataNB[predictors], cleanDataNB[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(NB, cleanDataNB[predictors], cleanDataNB[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(NB, cleanDataNB[predictors], cleanDataNB[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the naive baye\\'s classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the naive baye\\'s classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the naive baye\\'s classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the Linear SVC classifier is:\n",
      "[ 0.85        0.84        0.8         0.86        0.845       0.8241206\n",
      "  0.87437186  0.82914573  0.81407035  0.82323232] \n",
      "And their mean is:\n",
      "  0.835994086595\n",
      "\n",
      "The 10 Fold precision of the Linear SVC classifier is:\n",
      "[ 0.8984375   0.86764706  0.84328358  0.9         0.8976378   0.86923077\n",
      "  0.89552239  0.87596899  0.86153846  0.86363636] \n",
      "And their mean is:\n",
      "  0.87729029109\n",
      "\n",
      "The 10 Fold recall of the Linear SVC classifier is:\n",
      " [ 0.87121212  0.89393939  0.85606061  0.88636364  0.86363636  0.86259542\n",
      "  0.91603053  0.86259542  0.85496183  0.87022901] \n",
      "And their mean is:\n",
      "  0.873762433495\n"
     ]
    }
   ],
   "source": [
    "cleanDataSVC = cleanData.drop(['state','fold','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "SVC = LinearSVC()\n",
    "\n",
    "SVC = SVC.fit(cleanDataSVC[predictors], cleanData[outcome])\n",
    "kFoldAccuracy = model_selection.cross_val_score(SVC, cleanDataSVC[predictors], cleanDataSVC[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(SVC, cleanDataSVC[predictors], cleanDataSVC[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(SVC, cleanDataSVC[predictors], cleanDataSVC[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the Linear SVC classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the Linear SVC classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the Linear SVC classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the decision tree classifier is:\n",
      "[ 0.785       0.75        0.785       0.755       0.775       0.7638191\n",
      "  0.79396985  0.75879397  0.79899497  0.76262626] \n",
      "And their mean is:\n",
      "  0.772820415207\n",
      "\n",
      "The 10 Fold precision of the decision tree classifier is:\n",
      "[ 0.84848485  0.8125      0.84496124  0.832       0.8203125   0.83333333\n",
      "  0.84732824  0.8358209   0.83333333  0.81617647] \n",
      "And their mean is:\n",
      "  0.832425086585\n",
      "\n",
      "The 10 Fold recall of the decision tree classifier is:\n",
      " [ 0.82575758  0.81818182  0.84848485  0.8030303   0.81060606  0.80916031\n",
      "  0.83206107  0.83206107  0.82442748  0.81679389] \n",
      "And their mean is:\n",
      "  0.822056442285\n"
     ]
    }
   ],
   "source": [
    "dirtyData = pd.read_csv(\"communities-crime-full.csv\",na_values='?')\n",
    "dirtyData.fillna(dirtyData.mean(),inplace=True)\n",
    "dirtyData = dirtyData.drop(['county','fold','state','community','communityname'], axis=1)\n",
    "\n",
    "dirtyData['highCrime'] = 0\n",
    "condition = dirtyData['ViolentCrimesPerPop'] > thresh\n",
    "dirtyData.loc[condition, 'highCrime'] = 1\n",
    "\n",
    "dirtyDataDT = dirtyData.drop(['ViolentCrimesPerPop'], axis=1)\n",
    "outcome = 'highCrime'\n",
    "predictors = list(dirtyDataDT)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "decisionTree = tree.DecisionTreeClassifier()\n",
    "\n",
    "kFoldAccuracy = model_selection.cross_val_score(decisionTree, dirtyDataDT[predictors], dirtyDataDT[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(decisionTree, dirtyDataDT[predictors], dirtyDataDT[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(decisionTree, dirtyDataDT[predictors], dirtyDataDT[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the decision tree classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the decision tree classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the decision tree classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the naive baye's classifier is:\n",
      "[ 0.71        0.715       0.67        0.68        0.68        0.69849246\n",
      "  0.74874372  0.70854271  0.72864322  0.65151515] \n",
      "And their mean is:\n",
      "  0.699093726207\n",
      "\n",
      "The 10 Fold precision of the naive baye's classifier is:\n",
      "[ 0.95121951  0.93103448  0.94594595  0.925       0.94736842  0.92771084\n",
      "  1.          0.96202532  0.93258427  0.90789474] \n",
      "And their mean is:\n",
      "  0.943078352829\n",
      "\n",
      "The 10 Fold recall of the naive baye's classifier is:\n",
      " [ 0.59090909  0.61363636  0.53030303  0.56060606  0.54545455  0.58778626\n",
      "  0.61832061  0.58015267  0.63358779  0.52671756] \n",
      "And their mean is:\n",
      "  0.578747397641\n"
     ]
    }
   ],
   "source": [
    "dirtyDataNB = dirtyData.drop(['ViolentCrimesPerPop'], axis=1)\n",
    "NB = GaussianNB()\n",
    "\n",
    "NB = NB.fit(dirtyDataNB[predictors], dirtyData[outcome])\n",
    "kFoldAccuracy = model_selection.cross_val_score(NB, dirtyDataNB[predictors], dirtyDataNB[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(NB, dirtyDataNB[predictors], dirtyDataNB[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(NB, dirtyDataNB[predictors], dirtyDataNB[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the naive baye\\'s classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the naive baye\\'s classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the naive baye\\'s classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the Linear SVC classifier is:\n",
      "[ 0.85        0.82        0.81        0.865       0.845       0.8241206\n",
      "  0.86934673  0.82914573  0.8040201   0.82828283] \n",
      "And their mean is:\n",
      "  0.834491599411\n",
      "\n",
      "The 10 Fold precision of the Linear SVC classifier is:\n",
      "[ 0.8984375   0.85820896  0.85074627  0.90076336  0.89147287  0.86363636\n",
      "  0.89473684  0.87596899  0.85384615  0.87022901] \n",
      "And their mean is:\n",
      "  0.875804631035\n",
      "\n",
      "The 10 Fold recall of the Linear SVC classifier is:\n",
      " [ 0.87121212  0.87121212  0.86363636  0.89393939  0.87121212  0.87022901\n",
      "  0.90839695  0.86259542  0.84732824  0.87022901] \n",
      "And their mean is:\n",
      "  0.872999074717\n"
     ]
    }
   ],
   "source": [
    "dirtyDataSVC = dirtyData.drop(['ViolentCrimesPerPop'], axis=1)\n",
    "SVC = LinearSVC()\n",
    "\n",
    "SVC = SVC.fit(dirtyDataSVC[predictors], dirtyData[outcome])\n",
    "kFoldAccuracy = model_selection.cross_val_score(SVC, dirtyDataSVC[predictors], dirtyDataSVC[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(SVC, dirtyDataSVC[predictors], dirtyDataSVC[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(SVC, dirtyDataSVC[predictors], dirtyDataSVC[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the Linear SVC classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the Linear SVC classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the Linear SVC classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iv.\tHow are these results similar and different from the previous results (with a fixed threshold of 0.1). What does this say about how to approach such a problem.\n",
    "As we changed the threshold the accuracy, precision and recall improved. We visually analyzed the threshold vs MSE and threshold vs Accuracy to determine the best threshold value. To decide the threshold for such problem we should choose the threshold such that we minimize the error while optimizing accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\tExperiment with other learning methods such as polynomial or other kernels in SVM, decision forests, boosting, etc. and show your results. Make sure to explain clearly what you did.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We experimented with bagging with Gaussian Naive Bayes and bagging with Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the Bagging with naive bayes classifier is:\n",
      "[ 0.8         0.8         0.79        0.745       0.76        0.79899497\n",
      "  0.8241206   0.75376884  0.7839196   0.76262626] \n",
      "And their mean is:\n",
      "  0.781843028273\n",
      "\n",
      "The 10 Fold precision of the Bagging with nauve bayes classifier is:\n",
      "[ 0.95238095  0.91150442  0.93396226  0.88679245  0.95789474  0.94117647\n",
      "  0.97979798  0.91752577  0.90384615  0.90196078] \n",
      "And their mean is:\n",
      "  0.928684199272\n",
      "\n",
      "The 10 Fold recall of the Bagging with naive bayes classifier is:\n",
      " [ 0.73484848  0.75757576  0.72727273  0.70454545  0.70454545  0.73282443\n",
      "  0.72519084  0.70992366  0.71755725  0.71755725] \n",
      "And their mean is:\n",
      "  0.72318413139\n"
     ]
    }
   ],
   "source": [
    "cleanDataGNB = cleanData.drop(['fold','state','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "outcome = 'highCrime'\n",
    "predictors = list(cleanDataGNB)\n",
    "predictors.remove(outcome)\n",
    "bagging = BaggingClassifier(GaussianNB(), max_samples=0.2, max_features=0.9)\n",
    "kFoldAccuracy = model_selection.cross_val_score(bagging, cleanDataGNB[predictors], cleanDataGNB[outcome], cv=10, scoring='accuracy')            \n",
    "kFoldPrecision = model_selection.cross_val_score(bagging, cleanDataGNB[predictors], cleanDataGNB[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(bagging, cleanDataGNB[predictors], cleanDataGNB[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the Bagging with naive bayes classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the Bagging with nauve bayes classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the Bagging with naive bayes classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the Bagging with naive bayes classifier is:\n",
      "[ 0.86        0.83        0.805       0.85        0.855       0.83417085\n",
      "  0.86432161  0.82914573  0.81407035  0.82828283] \n",
      "And their mean is:\n",
      "  0.8369991371\n",
      "\n",
      "The 10 Fold precision of the Bagging with nauve bayes classifier is:\n",
      "[ 0.89230769  0.87692308  0.86259542  0.89230769  0.8976378   0.87313433\n",
      "  0.90909091  0.87401575  0.85606061  0.87022901] \n",
      "And their mean is:\n",
      "  0.880430227584\n",
      "\n",
      "The 10 Fold recall of the Bagging with naive bayes classifier is:\n",
      " [ 0.85606061  0.86363636  0.87121212  0.87878788  0.84848485  0.88549618\n",
      "  0.90839695  0.86259542  0.85496183  0.87022901] \n",
      "And their mean is:\n",
      "  0.869986120749\n"
     ]
    }
   ],
   "source": [
    "cleanDataBG = cleanData.drop(['fold','state','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "outcome = 'highCrime'\n",
    "predictors = list(cleanDataBG)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "bagging = bagging = BaggingClassifier(LinearSVC(), max_samples=0.8, max_features=0.5)\n",
    "kFoldAccuracy = model_selection.cross_val_score(bagging, cleanDataGNB[predictors], cleanDataGNB[outcome], cv=10, scoring='accuracy')            \n",
    "kFoldPrecision = model_selection.cross_val_score(bagging, cleanDataGNB[predictors], cleanDataGNB[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(bagging, cleanDataGNB[predictors], cleanDataGNB[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the Bagging with naive bayes classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the Bagging with nauve bayes classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the Bagging with naive bayes classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i.\tWhat method gives the best results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results are given by bagging with Linear SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. What feature(s) seem to be most consistently predictive of high crime rates? How reliable is this conclusion?\n",
    "most high crimes features seem to be consistent across all models.We think these features are reliable predictores of high crime."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Find other data sets to combine with this data set that might improve results. \n",
    "#### i. Explain precisely what you did to combine the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following process was followed to combine the data:\n",
    "    1. Data was downloaded from: https://www.census.gov/did/www/saipe/downloads/estmod95/est95ALL.dat\n",
    "    2. Data was cleaned and EstPplInPoverty, PctEstPplInPoverty, EstMedHouseholdIncome attribute were selected and added to the communities clean data.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Give accuracy, precision, and recall results with and without the new data.\n",
    "##### New Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aggData = pd.read_csv(\"communities_aggregated_data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the naive baye's classifier is:\n",
      "[ 0.7761194   0.835       0.8         0.79899497  0.70351759  0.66834171\n",
      "  0.8040201   0.74874372  0.71356784  0.79396985] \n",
      "And their mean is:\n",
      "  0.764227518188\n",
      "\n",
      "The 10 Fold precision of the naive baye's classifier is:\n",
      "[ 0.86486486  0.93396226  0.94736842  0.94736842  0.93421053  0.87341772\n",
      "  0.91346154  1.          0.77868852  0.94680851] \n",
      "And their mean is:\n",
      "  0.914015079265\n",
      "\n",
      "The 10 Fold recall of the naive baye's classifier is:\n",
      " [ 0.76190476  0.792       0.72        0.72        0.568       0.552       0.76\n",
      "  0.6         0.76        0.712     ] \n",
      "And their mean is:\n",
      "  0.69459047619\n"
     ]
    }
   ],
   "source": [
    "aggData['highCrime'] = 0\n",
    "condition = aggData['ViolentCrimesPerPop'] > 0.1\n",
    "aggData.loc[condition, 'highCrime'] = 1\n",
    "\n",
    "aggDataNB = aggData.drop(['state','fold','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "NB = GaussianNB()\n",
    "\n",
    "NB = NB.fit(aggDataNB[predictors], aggData[outcome])\n",
    "\n",
    "kFoldAccuracy = model_selection.cross_val_score(NB, aggDataNB[predictors], aggDataNB[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(NB, aggDataNB[predictors], aggDataNB[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(NB, aggDataNB[predictors], aggDataNB[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the naive baye\\'s classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the naive baye\\'s classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the naive baye\\'s classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Old Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanDataNB = cleanData.drop(['state','fold','communityname','ViolentCrimesPerPop'], axis=1)\n",
    "NB = GaussianNB()\n",
    "\n",
    "NB = NB.fit(cleanDataNB[predictors], cleanData[outcome])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the naive baye's classifier is:\n",
      "[ 0.79        0.77        0.755       0.75        0.76        0.79396985\n",
      "  0.81407035  0.73869347  0.76884422  0.74242424] \n",
      "And their mean is:\n",
      "  0.768300213187\n",
      "\n",
      "The 10 Fold precision of the naive baye's classifier is:\n",
      "[ 0.95918367  0.90566038  0.93684211  0.91        0.95652174  0.95\n",
      "  0.98958333  0.92473118  0.92079208  0.91666667] \n",
      "And their mean is:\n",
      "  0.936998115723\n",
      "\n",
      "The 10 Fold recall of the naive baye's classifier is:\n",
      " [ 0.71212121  0.72727273  0.67424242  0.68939394  0.66666667  0.72519084\n",
      "  0.72519084  0.65648855  0.70992366  0.67175573] \n",
      "And their mean is:\n",
      "  0.695824658802\n"
     ]
    }
   ],
   "source": [
    "kFoldAccuracy = model_selection.cross_val_score(NB, cleanDataNB[predictors], cleanDataNB[outcome], cv=10, scoring='accuracy')\n",
    "kFoldPrecision = model_selection.cross_val_score(NB, cleanDataNB[predictors], cleanDataNB[outcome], cv=10, scoring='precision')\n",
    "kFoldRecall = model_selection.cross_val_score(NB, cleanDataNB[predictors], cleanDataNB[outcome], cv=10, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the naive baye\\'s classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldAccuracy)), np.mean(kFoldAccuracy))\n",
    "print ('\\nThe 10 Fold precision of the naive baye\\'s classifier is:\\n%s \\nAnd their mean is:\\n '%(str(kFoldPrecision)), np.mean(kFoldPrecision))\n",
    "print ('\\nThe 10 Fold recall of the naive baye\\'s classifier is:\\n %s \\nAnd their mean is:\\n '%(str(kFoldRecall)), np.mean(kFoldRecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii.\tDoes the added data help? What features help? Does it matter what learning method you use?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The added data doesn't help improve the performance of the data irrespective of the learning method used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
